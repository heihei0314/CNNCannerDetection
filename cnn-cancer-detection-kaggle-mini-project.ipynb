{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Source code\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-27T04:40:23.598337Z","iopub.execute_input":"2023-04-27T04:40:23.598775Z","iopub.status.idle":"2023-04-27T04:40:23.607030Z","shell.execute_reply.started":"2023-04-27T04:40:23.598726Z","shell.execute_reply":"2023-04-27T04:40:23.605783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Problem Statement\n\n>### The project is aimed to detect Cancer with small pathology images. It is going to use CNN approach to train and predict the data.\n>### There are 220025 images in training data using about 3.4MB. The images are labeled to either 0 or 1 referring their catergory (negative or positive result). 130908 are negative and 89117 are positive. and there seems to be no null entries. Since the test set is not labeled. 20% training set will be selected for validation. \n>### Each data is around 28kB file size. It is Tiff image file image with 96x96 pixel in RGB.","metadata":{"execution":{"iopub.status.busy":"2023-04-25T03:39:18.196504Z","iopub.execute_input":"2023-04-25T03:39:18.196909Z","iopub.status.idle":"2023-04-25T03:39:18.202222Z","shell.execute_reply.started":"2023-04-25T03:39:18.196875Z","shell.execute_reply":"2023-04-25T03:39:18.200755Z"}}},{"cell_type":"code","source":"dir_images_test = '/kaggle/input/histopathologic-cancer-detection/test/'\ndir_images_train = '/kaggle/input/histopathologic-cancer-detection/train/'\nlabels_train = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\nimages_train = labels_train\nimages_train['label'] = images_train['label'].astype(str)\nimages_train['id'] = labels_train['id'] + '.tif'\nprint(labels_train.info())\nplt.hist(images_train['label'])\nplt.show()\npd.Series(images_train['label']).value_counts()\nimageData = Image.open(dir_images_train+images_train['id'][0])\nprint(\"Image Meta Data:\", imageData)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:40:23.611278Z","iopub.execute_input":"2023-04-27T04:40:23.611565Z","iopub.status.idle":"2023-04-27T04:40:24.691260Z","shell.execute_reply.started":"2023-04-27T04:40:23.611538Z","shell.execute_reply":"2023-04-27T04:40:24.690148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis (EDA) \n> ### We could find that the images have various patterns. We could find points, edges and space area in the data. Majority are having intensive points. Some of them have a large space area. Few of them mainly contains edges and big points.","metadata":{}},{"cell_type":"code","source":"from tifffile import imread\nrows, cols = 10, 10\n\nfig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n\nfor i in range(10 * 10):\n    image = imread(dir_images_train + images_train['id'][i])\n\n    row, col = i // cols, i % cols\n\n    axes[row, col].imshow(image)\n    axes[row, col].axis('off')\n\nplt.subplots_adjust(wspace = 0.1, hspace = 0.3)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:40:24.694340Z","iopub.execute_input":"2023-04-27T04:40:24.695497Z","iopub.status.idle":"2023-04-27T04:42:47.395650Z","shell.execute_reply.started":"2023-04-27T04:40:24.695452Z","shell.execute_reply":"2023-04-27T04:42:47.394754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Architecture \n> ### A VGG-style model is going to be used\n> ### The first model is going to have 12 layers. The architecture is as follow:\n\n> ### Conv2D -> Conv2D -> MaxPool2D -> Conv2D -> Conv2D -> MaxPool2D -> Conv2D -> Conv2D -> MaxPool2D -> Flatten -> Dense -> Dense -> Output\n> ### As we could find 3 patterns in the training images. It is going to try the above structure to spot out those pattern.\n\n> ### Activation Functions\n> ### ReLU is going to be used for the hidden layer, since it has better converagnece, less computation. And sigmoid for output layer which is fitted to binary detection. ","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten, BatchNormalization, Activation, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\ngenerator = ImageDataGenerator(validation_split=0.2)\nbatchSize=1000\ndata_train = generator.flow_from_dataframe(\n    dataframe = images_train,\n    x_col='id', # filenames\n    y_col='label', # labels\n    directory=dir_images_train,\n    subset='training',\n    class_mode='binary',\n    batch_size=batchSize,\n    target_size=(96, 96))\n\ndata_validate=generator.flow_from_dataframe(\n    dataframe=images_train,\n    x_col='id', # filenames\n    y_col='label', # labels\n    directory=dir_images_train,\n    subset=\"validation\",\n    class_mode='binary',\n    batch_size=batchSize,\n    target_size=(96, 96))","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:42:47.396912Z","iopub.execute_input":"2023-04-27T04:42:47.397972Z","iopub.status.idle":"2023-04-27T04:50:43.598438Z","shell.execute_reply.started":"2023-04-27T04:42:47.397933Z","shell.execute_reply":"2023-04-27T04:50:43.597262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = keras.models.Sequential()\nmodel1.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu', input_shape = (96, 96, 3)))\nmodel1.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu'))\nmodel1.add(MaxPool2D(pool_size=(2,2)))\n\nmodel1.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\nmodel1.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\nmodel1.add(MaxPool2D(pool_size=(2,2)))\n\nmodel1.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\nmodel1.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\nmodel1.add(MaxPool2D(pool_size=(2,2)))\n\nmodel1.add(Flatten())\nmodel1.add(Dense(units=256, activation='relu'))\nmodel1.add(Dense(units=1, activation='sigmoid'))\n#from keras.layers import PReLU\n#from keras.initializers import Constant\n#model1.add(PReLU(alpha_initializer=Constant(value=0.25)))\nmodel1.build(input_shape=(batchSize, 96, 96, 3))\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:50:43.601776Z","iopub.execute_input":"2023-04-27T04:50:43.602767Z","iopub.status.idle":"2023-04-27T04:50:43.762022Z","shell.execute_reply.started":"2023-04-27T04:50:43.602720Z","shell.execute_reply":"2023-04-27T04:50:43.761066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=0.01)\nmodel1.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\nhist1 = model1.fit(data_train, validation_data=data_validate, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:50:43.763207Z","iopub.execute_input":"2023-04-27T04:50:43.763885Z","iopub.status.idle":"2023-04-27T06:17:18.365800Z","shell.execute_reply.started":"2023-04-27T04:50:43.763844Z","shell.execute_reply":"2023-04-27T06:17:18.364766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n> ### The second model is going to have 16 layers. The architecture is as follow:\n\n> ### Conv2D -> Conv2D -> MaxPool2D -> Batch Normalization -> Conv2D -> Conv2D -> MaxPool2D -> Batch Normalization -> Conv2D -> Conv2D -> MaxPool2D -> Batch Normalization -> Flatten -> Dense -> Dropout -> Dense -> Output\n> ### As the loss and accuracy of the first model are too much consistant. It is going to normalize after each pooling layer and include dropout layer, in order to increase the learning effectiveness and efficiency.  \n\n> ### Activation Functions\n> ### It has no changes from the first model. ","metadata":{}},{"cell_type":"code","source":"model2 = keras.models.Sequential()\nmodel2.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu', input_shape = (96, 96, 3)))\nmodel2.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\nmodel2.add(BatchNormalization())\n\nmodel2.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\nmodel2.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\nmodel2.add(BatchNormalization())\n\nmodel2.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\nmodel2.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\nmodel2.add(BatchNormalization())\n\nmodel2.add(Flatten())\nmodel2.add(Dense(units=256, activation='relu'))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(units=1, activation='sigmoid'))\nmodel2.build(input_shape=(batchSize, 96, 96, 3))\nmodel2.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:17:18.367684Z","iopub.execute_input":"2023-04-27T06:17:18.368010Z","iopub.status.idle":"2023-04-27T06:17:18.566653Z","shell.execute_reply.started":"2023-04-27T06:17:18.367980Z","shell.execute_reply":"2023-04-27T06:17:18.565779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=0.01)\nmodel2.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\nhist2 = model2.fit(data_train, validation_data=data_validate, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:17:18.567821Z","iopub.execute_input":"2023-04-27T06:17:18.568213Z","iopub.status.idle":"2023-04-27T07:44:48.802336Z","shell.execute_reply.started":"2023-04-27T06:17:18.568172Z","shell.execute_reply":"2023-04-27T07:44:48.801179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Results and Analysis \n\n> ### In the first model,\nThe execution time is fair. The final training accuracy was accuracy: 0.5947, and validation accuracy was val_accuracy: 0.5961. It is a fair model. We could not see underfitting or overfitting. However the accuracy are consistant. There is no signicficant improvement among the early epoches.\n\n\n> ### In the second model,\nThe execution time is fair. The final training accuracy was accuracy: 0.8953, and validation accuracy was val_accuracy: 0.8266. It is good-fit model. It has a nice training curve. It might have over-fitting but not enough evidence. \n        \n","metadata":{}},{"cell_type":"code","source":"plt.plot(hist1.history[\"accuracy\"])\nplt.plot(hist1.history['val_accuracy'])\nplt.title(\"Model 1 Evaluation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n\nplt.show()\nplt.plot(hist2.history[\"accuracy\"])\nplt.plot(hist2.history['val_accuracy'])\nplt.title(\"Model 2 Evaluation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T07:44:48.805683Z","iopub.execute_input":"2023-04-27T07:44:48.806032Z","iopub.status.idle":"2023-04-27T07:44:49.287824Z","shell.execute_reply.started":"2023-04-27T07:44:48.806001Z","shell.execute_reply":"2023-04-27T07:44:49.286832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Conclusion \n> ### Comparing two models,\nThe first model performs fair in terms of accuracy. However the accuracy is consistant. After normalized and dropout, the second model solved the issue. The accuracy did improve much.  \n\n> ### Future Improvement\nIt is suggested to conduct L2 regularization, to better improve the training efficiency. And also increase the epoch and reduce the learning rate to have better training performance if there is enough resource. Maybe SGD or RMSProp could be tried as alternative optimization method.","metadata":{}},{"cell_type":"code","source":"#Submission\nimages_test = pd.DataFrame({'id':os.listdir(dir_images_test)})\n\ngenerator_test = ImageDataGenerator()\nbatchSize = 1\ndata_test = generator_test.flow_from_dataframe(\n    dataframe = images_test,\n    x_col='id', # filenames\n    directory=dir_images_test,\n    class_mode=None,\n    batch_size=batchSize,\n    target_size=(96, 96),\n    shuffle=False)\npredictions = model2.predict(data_test, verbose=1)\nprint(predictions)\npred = np.transpose(predictions)[0]\n\nprint(pred)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['id'] = images_test['id'].apply(lambda x: x.split('.')[0])\nsubmission_df['label'] = list(map(lambda x: 0 if x < 0.5 else 1, pred))\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T07:55:01.026325Z","iopub.execute_input":"2023-04-27T07:55:01.027972Z","iopub.status.idle":"2023-04-27T08:00:09.491144Z","shell.execute_reply.started":"2023-04-27T07:55:01.027927Z","shell.execute_reply":"2023-04-27T08:00:09.490060Z"},"trusted":true},"execution_count":null,"outputs":[]}]}